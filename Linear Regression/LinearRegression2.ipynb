{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "\n",
    "data_X = pd.read_csv('./r_train_X.csv', encoding = 'big5')  #r_train_X.csv文件要与python代码文件(.py或.ipynb)在同一个目录下才行\n",
    "data_y = pd.read_csv('./r_train_y.csv', encoding = 'big5')  #r_train_y.csv文件要与python代码文件(.py或.ipynb)在同一个目录下才行\n",
    "X = data_X.to_numpy()  #将数据转换成numpy数据\n",
    "y = data_y.to_numpy()  #将数据转换成numpy数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数功能：预处理数据，使所有维度的数据都缩放到零均值，标准差为1\n",
    "#    输入：X 待处理数据，每一列为同一个属性在不同样本上的取值\n",
    "#    输出：X_processed 缩放后的数据，维度和 X 一样\n",
    "#          mean_X 每一列的均值，维度为 (1, n)\n",
    "#          std_X 每一列的标准差，维度为 (1, n)\n",
    "def preprocessData(X):\n",
    "    mean_X = np.mean(X, axis = 0, keepdims = 1)\n",
    "    std_X = np.std(X, axis = 0, keepdims = 1, ddof=1)\n",
    "    X_processed = (X - mean_X) / (std_X + 0.00000001)\n",
    "    return X_processed, mean_X, std_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数功能：在数据前增加一列或一行全为1\n",
    "#    输入：X_train 原始数据 (m, n)\n",
    "#          ax = 1表示在最左边加1列， = 0 表示在最上面加一行\n",
    "#    输出：X 加完后的数组  (m + 1, n) 或 (m, n + 1)\n",
    "def expendOneCol(X_train, ax = 1):\n",
    "    X = np.insert(X_train, 0, values = np.ones((1,X_train.shape[(ax+1)%2])), axis = ax)\n",
    "    return X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数功能：初始化参数\n",
    "#    输入：m 维度\n",
    "#    输出：parameters 初始化为 0 的数组 (m, 1)\n",
    "def initialParameters(m):\n",
    "    parameters = np.zeros((m, 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数功能：计算假设函数的结果，公式如上\n",
    "#     输入：X (m, n) 是一个 m 行 n 列的矩阵，m 是样本个数，n 是 theta 的维度\n",
    "#           parameters 是一个 (n, 1) 的 n 维向量，其就是公式中的 theta\n",
    "#     输出：y (m, 1) 是一个 m 维的列向量，每一行是一个样本的输出\n",
    "def hypothese(X, parameters):\n",
    "    h = np.dot(X, parameters)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数功能：计算梯度\n",
    "#    输入：X_train 训练数据\n",
    "#          y 标签数据\n",
    "#          h 假设函数结果\n",
    "#    输出：grad 梯度\n",
    "def calculateGrad(X_train, y, h):\n",
    "    grad = np.dot(X_train.T, h - y)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数功能：计算损失值\n",
    "#    输入：y 标签\n",
    "#          h 假设函数结果\n",
    "#    输出：J 损失值\n",
    "def calLossFunction(y, h):\n",
    "    sub = (h - y)\n",
    "    J = np.dot(sub.T, sub) / 2\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegressionTrain(X_train, y, learningRate = 0.000002, iteration = 1000):\n",
    "    X_processed, mean_X, std_X = preprocessData(X)\n",
    "    X_train = expendOneCol(X_processed)\n",
    "    (m, n) = X_train.shape\n",
    "    parameters = initialParameters(n)\n",
    "    lossHistory = np.zeros((iteration, 1))\n",
    "    \n",
    "    for ite in range(iteration):\n",
    "        h = hypothese(X_train, parameters)\n",
    "        grads = calculateGrad(X_train, y, h)\n",
    "        parameters = parameters - learningRate * grads\n",
    "        lossHistory[ite] = calLossFunction(y, h)\n",
    "    \n",
    "    return lossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = linearRegressionTrain(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "itera = np.arange(1000)\n",
    "plt.plot(itera, his)\n",
    "#plt.plot(itera, loss_val_history)  #画出在验证集上损失值变化曲线\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearRegressionModel:\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        X_train       用于存储训练集数据\n",
    "        y_train       用于存储训练数据的标签\n",
    "        X_mean        用于存储各个属性的均值\n",
    "        X_std         用于存储各个属性的标准差\n",
    "        m             用于存储样本个数\n",
    "        n             用于存储属性个数（扩充后的）\n",
    "        parameters    用于存储参数数据\n",
    "        seed          用于存储随机数种子\n",
    "        method        用于存储训练方法，默认为 None 表示未设定\n",
    "        iteration     用于存储迭代次数\n",
    "        miniBatchSize 用于记录 miniBatch 的尺寸，默认为 64\n",
    "        recoedTimes   用于存储记录损失值的次数\n",
    "        lossHistory   用于存储记录的损失值\n",
    "        \"\"\"\n",
    "        (temp_X, self.X_mean, self.X_std) = self.preprocessData(X)\n",
    "        self.X_train = self.expendOneCol(temp_X)\n",
    "        self.y_train = y       \n",
    "        self.m, self.n = self.X_train.shape \n",
    "        self.parameters = self.initialParameters(self.n) \n",
    "        self.seed = 0          \n",
    "        self.method = \"None\"   \n",
    "        self.iteration = 0\n",
    "        self.miniBatchSize = 64\n",
    "        self.recoedTimes = 0  \n",
    "        self.lossHistory = 0   \n",
    "        \n",
    "    def preprocessData(self, X):\n",
    "        \"\"\"\n",
    "        函数功能：预处理数据，使所有维度的数据都缩放到零均值，标准差为1\n",
    "            输入：X 待处理数据，每一列为同一个属性在不同样本上的取值\n",
    "            输出：X_processed 缩放后的数据，维度和 X 一样\n",
    "                  mean_X 每一列的均值，维度为 (1, n)\n",
    "                  std_X 每一列的标准差，维度为 (1, n)\n",
    "        \"\"\"     \n",
    "        X_mean = np.mean(X, axis = 0, keepdims = 1)\n",
    "        X_std = np.std(X, axis = 0, keepdims = 1, ddof=1)\n",
    "        X_processed = (X - X_mean) / (X_std + 0.00000001)\n",
    "        return X_processed, X_mean, X_std\n",
    "    \n",
    "    def expendOneCol(self, X_train, ax = 1):\n",
    "        \"\"\"\n",
    "        函数功能：计算假设函数的结果，公式如上\n",
    "            输入：X (m, n) 是一个 m 行 n 列的矩阵，m 是样本个数，n 是 theta 的维度\n",
    "                  parameters 是一个 (n, 1) 的 n 维向量，其就是公式中的 theta\n",
    "            输出：y (m, 1) 是一个 m 维的列向量，每一行是一个样本的输出\n",
    "        \"\"\"\n",
    "        X = np.insert(X_train, 0, values = np.ones((1,X_train.shape[(ax+1)%2])), axis = ax)\n",
    "        return X;\n",
    "    \n",
    "    def initialParameters(self, m):\n",
    "        \"\"\"\n",
    "        函数功能：初始化参数\n",
    "            输入：m 维度\n",
    "            输出：parameters 初始化为 0 的数组 (m, 1)\"\"\"\n",
    "        parameters = np.zeros((m, 1))\n",
    "        return parameters\n",
    "    \n",
    "    def hypothese(X, parameters):\n",
    "        \"\"\"\n",
    "        函数功能：计算假设函数的结果，公式如上\n",
    "            输入：X (m, n) 是一个 m 行 n 列的矩阵，m 是样本个数，n 是 theta 的维度\n",
    "                  parameters 是一个 (n, 1) 的 n 维向量，其就是公式中的 theta\n",
    "            输出：y (m, 1) 是一个 m 维的列向量，每一行是一个样本的输出\n",
    "        \"\"\"\n",
    "        h = np.dot(X, parameters)\n",
    "        return h\n",
    "    \n",
    "    def calculateGrad(X_train, y, h):\n",
    "        \"\"\"\n",
    "        函数功能：计算梯度\n",
    "            输入：X_train 训练数据\n",
    "                  y 标签数据\n",
    "                  h 假设函数结果\n",
    "            输出：grad 梯度\n",
    "        \"\"\"\n",
    "        grad = np.dot(X_train.T, h - y)\n",
    "        return grad\n",
    "    \n",
    "    def calLossFunction(y, h):\n",
    "        \"\"\"\n",
    "        函数功能：计算损失值\n",
    "            输入：y 标签\n",
    "                  h 假设函数结果\n",
    "            输出：J 损失值\n",
    "        \"\"\"\n",
    "        sub = (h - y)\n",
    "        J = np.dot(sub.T, sub) / 2\n",
    "        return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.25380287e+01, 2.25447531e+01, 2.25513007e+01, 2.25553707e+01,\n",
       "        2.25578482e+01, 2.25580959e+01, 2.25581136e+01, 2.25571226e+01,\n",
       "        2.25530526e+01, 1.70237126e+00, 1.70228278e+00, 1.70215891e+00,\n",
       "        1.70212352e+00, 1.70199965e+00, 1.70194656e+00, 1.70187577e+00,\n",
       "        1.70184038e+00, 1.70176960e+00, 3.89012564e-01, 3.88931163e-01,\n",
       "        3.88959476e-01, 3.89170058e-01, 3.89341709e-01, 3.89385949e-01,\n",
       "        3.89308087e-01, 3.89056804e-01, 3.88511768e-01, 1.40143337e-01,\n",
       "        1.40185808e-01, 1.40440630e-01, 1.40799858e-01, 1.41019289e-01,\n",
       "        1.41100690e-01, 1.41134313e-01, 1.41097151e-01, 1.40895417e-01,\n",
       "        2.14765528e+00, 2.15061051e+00, 2.15280481e+00, 2.15515838e+00,\n",
       "        2.15565387e+00, 2.15591931e+00, 2.15558308e+00, 2.15372500e+00,\n",
       "        2.14777915e+00, 1.01154486e+01, 1.01190232e+01, 1.01287206e+01,\n",
       "        1.01442577e+01, 1.01574058e+01, 1.01650858e+01, 1.01686073e+01,\n",
       "        1.01672978e+01, 1.01591754e+01, 1.22488055e+01, 1.22551407e+01,\n",
       "        1.22672447e+01, 1.22854716e+01, 1.22992568e+01, 1.23070253e+01,\n",
       "        1.23103522e+01, 1.23071138e+01, 1.22930809e+01, 3.18985135e+01,\n",
       "        3.19434613e+01, 3.19815254e+01, 3.20068306e+01, 3.20197841e+01,\n",
       "        3.20316050e+01, 3.20414617e+01, 3.20502566e+01, 3.20596178e+01,\n",
       "        4.25811361e+01, 4.25836135e+01, 4.26021943e+01, 4.26340471e+01,\n",
       "        4.26715626e+01, 4.27064236e+01, 4.27350911e+01, 4.27614581e+01,\n",
       "        4.27747301e+01, 2.13369315e+01, 2.13236595e+01, 2.13229517e+01,\n",
       "        2.13317997e+01, 2.13484339e+01, 2.13592285e+01, 2.13659529e+01,\n",
       "        2.13678995e+01, 2.13719696e+01, 2.03999292e-01, 2.03397629e-01,\n",
       "        2.02725181e-01, 2.02654397e-01, 2.02477438e-01, 2.02265086e-01,\n",
       "        2.02194302e-01, 2.02194302e-01, 2.02194302e-01, 7.31909397e+01,\n",
       "        7.31504159e+01, 7.31164396e+01, 7.30891878e+01, 7.30702531e+01,\n",
       "        7.30578659e+01, 7.30477792e+01, 7.30421164e+01, 7.30447708e+01,\n",
       "        2.76105114e+00, 2.76262608e+00, 2.76607680e+00, 2.76827110e+00,\n",
       "        2.76984604e+00, 2.77106707e+00, 2.77200495e+00, 2.77363299e+00,\n",
       "        2.77317289e+00, 1.83937356e+00, 1.83930278e+00, 1.83946204e+00,\n",
       "        1.83976287e+00, 1.83986905e+00, 1.83990444e+00, 1.83979827e+00,\n",
       "        1.83969209e+00, 1.83942665e+00, 1.56326951e+02, 1.56556645e+02,\n",
       "        1.56734843e+02, 1.56767227e+02, 1.56746346e+02, 1.56706530e+02,\n",
       "        1.56733959e+02, 1.56744399e+02, 1.56786339e+02, 1.58608193e+02,\n",
       "        1.58769227e+02, 1.58932667e+02, 1.58912670e+02, 1.58869669e+02,\n",
       "        1.58969474e+02, 1.58981331e+02, 1.58991594e+02, 1.58995311e+02,\n",
       "        2.29716864e+00, 2.29971686e+00, 2.30187577e+00, 2.30265440e+00,\n",
       "        2.30385772e+00, 2.30435321e+00, 2.30571580e+00, 2.30559193e+00,\n",
       "        2.30642364e+00, 1.71413909e+00, 1.71461688e+00, 1.71445762e+00,\n",
       "        1.71451071e+00, 1.71481154e+00, 1.71516546e+00, 1.71557247e+00,\n",
       "        1.71636878e+00, 1.71704123e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
